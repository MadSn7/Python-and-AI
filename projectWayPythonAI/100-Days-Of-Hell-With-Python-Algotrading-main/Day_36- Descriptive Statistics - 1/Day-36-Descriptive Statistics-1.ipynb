{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Descriptive Statistics Part 1\n",
    "\n",
    "#### What is Statistics?\n",
    "Statistics is the science of collecting, analyzing, interpreting, and presenting data. It provides tools for understanding data and making informed decisions based on data analysis.\n",
    "\n",
    "**Examples**:\n",
    "1. **Analyzing Historical Stock Prices**: A trader collects historical stock prices to determine trends and predict future prices.\n",
    "2. **Volatility Analysis**: Calculating the volatility of different stocks to assess their risk.\n",
    "3. **Performance Metrics**: Analyzing the performance metrics of various trading strategies to determine their effectiveness.\n",
    "4. **Market Sentiment**: Analyzing news articles and social media posts to gauge market sentiment.\n",
    "\n",
    "**Python Example**:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Collecting historical stock price data\n",
    "data = pd.read_csv('historical_stock_prices.csv')\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "#### Types of Statistics\n",
    "1. **Descriptive Statistics**: Summarizes or describes the characteristics of a dataset.\n",
    "2. **Inferential Statistics**: Makes inferences about populations based on samples.\n",
    "\n",
    "**Examples**:\n",
    "1. **Descriptive**: \n",
    "- Calculating the average daily trading volume of a stock over a month.\n",
    "- Creating a histogram of daily returns for a stock to understand its volatility.\n",
    "2. **Inferential**: \n",
    "- Using sample data from a specific trading   period  to estimate the performance of a trading algorithm.\n",
    "- Performing a hypothesis test to determine if a new trading strategy is more effective than the existing one.\n",
    "\n",
    "**Python Example**:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Descriptive statistics\n",
    "data = pd.read_csv('historical_stock_prices.csv')\n",
    "mean_price = data['Close'].mean()\n",
    "median_price = data['Close'].median()\n",
    "print(f\"Mean Price: {mean_price}, Median Price: {median_price}\")\n",
    "\n",
    "# Inferential statistics (e.g., t-test)\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "sample1 = data['Close'][:50]\n",
    "sample2 = data['Close'][50:100]\n",
    "t_stat, p_val = ttest_ind(sample1, sample2)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")\n",
    "```\n",
    "\n",
    "#### Population vs Sample\n",
    "- **Population**: The entire set of subjects or items that you are interested in studying.\n",
    "- **Sample**: A subset of the population used to make inferences about the population.\n",
    "\n",
    "**Examples**:\n",
    "1. **Population**: \n",
    "- All trades made in the stock market in a year.\n",
    "- All customers of a trading platform.\n",
    "2. **Sample**: \n",
    "- Trades made in the stock market in January.\n",
    "- Customers who executed trades during a specific week.\n",
    "\n",
    "**3 Important factors need to be considered while creating samples**:\n",
    "1. **Sample Size** \n",
    "2. **Random**\n",
    "3. **Representative**\n",
    "\n",
    "\n",
    "**Python Example**:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Population data (all trades in a year)\n",
    "data = pd.read_csv('all_trades_year.csv')\n",
    "\n",
    "# Sample data (trades in January)\n",
    "sample_data = data[data['Date'].str.contains('2023-01')]\n",
    "print(sample_data.head())\n",
    "```\n",
    "\n",
    "\n",
    "### Parameter vs Statistic\n",
    "\n",
    "In the context of statistics, a **parameter** is a numerical value that describes a characteristic of a population, whereas a **statistic** is a numerical value that describes a characteristic of a sample taken from that population.\n",
    "\n",
    "#### Parameter\n",
    "- A parameter is a fixed, often unknown number that describes some characteristic of a population.\n",
    "- Examples include population mean (μ), population variance (σ²), population proportion (p), etc.\n",
    "\n",
    "#### Statistic\n",
    "- A statistic is a numerical value that describes some characteristic of a sample.\n",
    "- Examples include sample mean (\\(\\overline{x}\\)), sample variance (s²), sample proportion (\\(\\hat{p}\\)), etc.\n",
    "\n",
    "### Inferential Statistics\n",
    "\n",
    "Inferential statistics involves making predictions or inferences about a population based on a sample of data drawn from that population. It uses various methods to analyze sample data and make generalizations about the larger population.\n",
    "\n",
    "\n",
    "### Subtopics Under Inferential Statistics \n",
    "\n",
    "1. **Hypothesis Testing**\n",
    "   - **Purpose**: To evaluate the performance or efficacy of trading strategies.\n",
    "   - **Example**: Testing whether a new trading algorithm has a statistically significant difference in average returns compared to an existing algorithm.\n",
    "\n",
    "2. **Confidence Intervals**\n",
    "   - **Purpose**: To estimate the uncertainty of trading metrics such as expected returns, volatility, and drawdowns.\n",
    "   - **Example**: Estimating the confidence interval for the average yearly return of a trading strategy to gauge its reliability.\n",
    "\n",
    "3. **Regression Analysis**\n",
    "   - **Purpose**: To model the relationships between market variables or to predict future price movements based on historical data.\n",
    "   - **Example**: Using multiple linear regression to predict stock prices based on economic indicators like GDP growth rate, interest rates, and unemployment rates.\n",
    "\n",
    "4. **Analysis of Variance (ANOVA)**\n",
    "   - **Purpose**: To compare the performance of multiple trading strategies across different market conditions.\n",
    "   - **Example**: Determining if there are significant differences in the returns of different sector-based trading strategies during different economic cycles.\n",
    "\n",
    "5. **Chi-Square Tests**\n",
    "   - **Purpose**: To analyze categorical data within market research or trading patterns.\n",
    "   - **Example**: Testing if there is a significant relationship between the day of the week and the frequency of trading anomalies.\n",
    "\n",
    "6. **Sampling Techniques**\n",
    "   - **Purpose**: To ensure representative and unbiased samples for back-testing trading strategies.\n",
    "   - **Example**: Employing stratified random sampling to select a diverse range of historical data periods for robust strategy testing.\n",
    "\n",
    "7. **Bayesian Statistics**\n",
    "   - **Purpose**: To update probabilities of trading outcomes as new data becomes available, accommodating for changing market conditions.\n",
    "   - **Example**: Using Bayesian inference to update the probability of a stock's outperformance based on new quarterly earnings reports.\n",
    "\n",
    "8. **Time Series Analysis**\n",
    "   - **Purpose**: To analyze sequential data points collected over time, crucial for financial data analysis.\n",
    "   - **Example**: Applying ARIMA models to forecast future stock prices or volatility patterns.\n",
    "\n",
    "9. **Monte Carlo Simulations**\n",
    "   - **Purpose**: To assess risk and uncertainty in prediction models by simulating a wide range of possible outcomes.\n",
    "   - **Example**: Using Monte Carlo simulations to estimate the potential drawdown of a trading strategy under various market scenarios.\n",
    "\n",
    "10. **Causal Inference**\n",
    "    - **Purpose**: To determine causal relationships rather than mere correlations, important for strategy validation.\n",
    "    - **Example**: Identifying whether changes in interest rates directly cause shifts in stock market indices.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Types of Data\n",
    "1. **Quantitative Data**: Numeric data that can be measured.\n",
    "   - **Discrete**: Countable data, like the number of trades made.\n",
    "   - **Continuous**: Measurable data, like the price of a stock.\n",
    "2. **Qualitative Data**: Descriptive data that can be categorized.\n",
    "   - **Nominal**: Categories without a specific order, like types of stocks.\n",
    "   - **Ordinal**: Categories with a specific order, like stock ratings.\n",
    "\n",
    "**Examples**:\n",
    "1. **Quantitative - Discrete**: Number of trades made per day.\n",
    "2. **Quantitative - Continuous**: Daily closing price of a stock.\n",
    "3. **Qualitative - Nominal**: Sectors of stocks (e.g., technology, healthcare).\n",
    "4. **Qualitative - Ordinal**: Stock ratings (e.g., AAA, AA, A).\n",
    "\n",
    "**Python Example**:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Quantitative data\n",
    "data = pd.read_csv('trades_data.csv')\n",
    "print(data['Volume'].describe())  # Discrete\n",
    "print(data['Close'].describe())   # Continuous\n",
    "\n",
    "# Qualitative data\n",
    "print(data['Sector'].value_counts())  # Nominal\n",
    "print(data['Rating'].value_counts())  # Ordinal\n",
    "```\n",
    "\n",
    "### ** Measure of Central Tendency **\n",
    "\n",
    "\n",
    "### 1. **Mean (Arithmetic Average)**\n",
    "   - **Formula**: The mean is calculated by adding up all the numbers in the data set and then dividing by the number of data points:\n",
    "   \\[\n",
    "   \\text{Mean} = \\frac{\\sum_{i=1}^n x_i}{n}\n",
    "   \\]\n",
    "   where \\( x_i \\) are the values in the dataset and \\( n \\) is the number of values.\n",
    "\n",
    "### 2. **Median**\n",
    "   - **Formula**: If the number of observations \\( n \\) is odd, the median is the middle value. If \\( n \\) is even, it is the average of the two middle numbers. Mathematically, it's not expressed in a simple formula but determined through the ordered data set.\n",
    "\n",
    "### 3. **Mode**\n",
    "   - **Formula**: The mode is the value or values in the data set that appear most frequently. It is more of a counting and comparison operation rather than a formulaic calculation.\n",
    "\n",
    "### 4. **Weighted Mean**\n",
    "   - **Formula**: The weighted mean considers the importance (weight) of each value:\n",
    "   \\[\n",
    "   \\text{Weighted Mean} = \\frac{\\sum_{i=1}^n (w_i \\times x_i)}{\\sum_{i=1}^n w_i}\n",
    "   \\]\n",
    "   where \\( w_i \\) are the weights assigned to each value \\( x_i \\).\n",
    "\n",
    "### 5. **Trimmed Mean**\n",
    "   - **Description**: The trimmed mean is calculated by removing a certain percentage of the smallest and largest values from the data set, and then calculating the mean of the remaining data. This is particularly useful in reducing the effect of outliers or extreme values.\n",
    "   - **Formula**: If you trim \\( p\\% \\) of data from both ends of an ordered dataset, you remove \\( p\\% \\) of \\( n \\) observations from both the lower and upper ends. The trimmed mean is then:\n",
    "   \\[\n",
    "   \\text{Trimmed Mean} = \\frac{\\sum_{i=k+1}^{n-k} x_i}{n-2k}\n",
    "   \\]\n",
    "   where \\( x_i \\) are the ordered values, \\( n \\) is the total number of observations, and \\( k \\) is the number of observations to trim from each end (\\( k = \\frac{p}{100} \\times n \\)).\n",
    "\n",
    "### Application in Algorithmic Trading\n",
    "\n",
    "- **Mean and Weighted Mean**: Useful for calculating average prices, returns, or other financial indicators where all values are relevant or where recent values need more emphasis.\n",
    "- **Median**: Offers a robust measure of central tendency when data may be skewed by outliers, such as during market spikes.\n",
    "- **Mode**: Helpful in identifying the most common values, which can indicate typical market behavior.\n",
    "- **Trimmed Mean**: Effective in scenarios where outliers (due to market anomalies or errors in data collection) might skew the average, providing a more representative measure of central tendency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Setup and Data\n",
    "\n",
    "First, we'll set up a sample dataset using `pandas`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset of daily returns (%) of a stock\n",
    "data = {'Daily Returns': [2, -1, 3, 4, 2, 2, 100, 1, 0, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "### 1. **Mean (Arithmetic Average)**\n",
    "\n",
    "Calculating the mean using pandas:\n",
    "\n",
    "```python\n",
    "mean_return = df['Daily Returns'].mean()\n",
    "print(\"Mean Daily Return:\", mean_return)\n",
    "```\n",
    "\n",
    "### 2. **Median**\n",
    "\n",
    "Calculating the median using pandas:\n",
    "\n",
    "```python\n",
    "median_return = df['Daily Returns'].median()\n",
    "print(\"Median Daily Return:\", median_return)\n",
    "```\n",
    "\n",
    "### 3. **Mode**\n",
    "\n",
    "Calculating the mode using pandas:\n",
    "\n",
    "```python\n",
    "mode_return = df['Daily Returns'].mode()\n",
    "print(\"Mode of Daily Returns:\", mode_return.tolist())\n",
    "```\n",
    "\n",
    "### 4. **Weighted Mean**\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "weights = np.linspace(start=1, stop=len(df), num=len(df))\n",
    "weighted_mean = np.average(df['Daily Returns'], weights=weights)\n",
    "print(\"Weighted Mean of Daily Returns:\", weighted_mean)\n",
    "```\n",
    "\n",
    "### 5. **Trimmed Mean**\n",
    "\n",
    "\n",
    "```python\n",
    "def trimmed_mean(series, percentage=0.1):\n",
    "    # Determine the number of elements to cut from each end\n",
    "    trim_count = int(len(series) * percentage)\n",
    "    # Sort the series, drop the specified percentage from both ends, and calculate the mean\n",
    "    return series.sort_values().iloc[trim_count:-trim_count].mean()\n",
    "\n",
    "# Calculating trimmed mean of daily returns\n",
    "trimmed_return = trimmed_mean(df['Daily Returns'], 0.1)\n",
    "print(\"Trimmed Mean of Daily Returns:\", trimmed_return)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###  Measures of Dispersion\n",
    "\n",
    "**1. Range**\n",
    "- **Description**: The range provides a simple measure of the overall spread between the smallest and largest values in a dataset.\n",
    "- **Mathematical Formula**: \n",
    "  \\[\n",
    "  \\text{Range} = \\text{Maximum value} - \\text{Minimum value}\n",
    "  \\]\n",
    "\n",
    "**2. Variance**\n",
    "- **Description**: Variance measures the average squared deviations from the mean, giving a sense of how spread out the data points are around the mean.\n",
    "- **Mathematical Formula**: \n",
    "  \\[\n",
    "  \\text{Variance} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}\n",
    "  \\]\n",
    "  where \\( x_i \\) are the values and \\( \\bar{x} \\) is the sample mean.\n",
    "\n",
    "**3. Standard Deviation**\n",
    "- **Description**: Standard deviation is the square root of the variance and provides a measure of the spread of data points around the mean in the same units as the data.\n",
    "- **Mathematical Formula**: \n",
    "  \\[\n",
    "  \\text{Standard Deviation} = \\sqrt{\\text{Variance}}\n",
    "  \\]\n",
    "\n",
    "**4. Interquartile Range (IQR)**\n",
    "- **Description**: The interquartile range is the difference between the 75th percentile (Q3) and the 25th percentile (Q1) of the data, focusing on the central spread of the dataset and minimizing the effect of outliers.\n",
    "- **Mathematical Formula**: \n",
    "  \\[\n",
    "  \\text{IQR} = Q3 - Q1\n",
    "  \\]\n",
    "\n",
    "**5. Mean Absolute Deviation (MAD)**\n",
    "- **Description**: Mean Absolute Deviation represents the average of the absolute deviations from the dataset's mean, providing a robust measure of variability that is less sensitive to outliers than variance.\n",
    "- **Mathematical Formula**: \n",
    "  \\[\n",
    "  \\text{MAD} = \\frac{\\sum_{i=1}^n |x_i - \\bar{x}|}{n}\n",
    "  \\]\n",
    "  where \\( x_i \\) are the values and \\( \\bar{x} \\) is the sample mean.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset of daily returns (%) of a stock\n",
    "data = {'Daily Returns': [2, -1, 3, 4, 2, 2, 100, 1, 0, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Range\n",
    "range_return = df['Daily Returns'].max() - df['Daily Returns'].min()\n",
    "\n",
    "# Calculate Variance\n",
    "variance_return = df['Daily Returns'].var()\n",
    "\n",
    "# Calculate Standard Deviation\n",
    "std_dev_return = df['Daily Returns'].std()\n",
    "\n",
    "# Calculate Interquartile Range\n",
    "Q1 = df['Daily Returns'].quantile(0.25)\n",
    "Q3 = df['Daily Returns'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate Mean Absolute Deviation\n",
    "mad_return = df['Daily Returns'].mad()\n",
    "\n",
    "# Print all results\n",
    "print(\"Range of Daily Returns:\", range_return)\n",
    "print(\"Variance of Daily Returns:\", variance_return)\n",
    "print(\"Standard Deviation of Daily Returns:\", std_dev_return)\n",
    "print(\"Interquartile Range of Daily Returns:\", IQR)\n",
    "print(\"Mean Absolute Deviation of Daily Returns:\", mad_return)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Coefficient of Variation\n",
    "\n",
    "The coefficient of variation (CV) is a measure of relative variability that describes the extent of variability in relation to the mean of the population. It is especially useful in comparing the degree of variation from one data series to another, even if the means are drastically different from each other.\n",
    "\n",
    "### Mathematical Formula\n",
    "\n",
    "The coefficient of variation is calculated as the ratio of the standard deviation to the mean, expressed as a percentage:\n",
    "\n",
    "\\[\n",
    "\\text{CV} = \\left(\\frac{\\text{Standard Deviation}}{\\text{Mean}}\\right) \\times 100\\%\n",
    "\\]\n",
    "\n",
    "This formula gives a normalized measure of dispersion, making it easier to compare variability across datasets with different units or scales.\n",
    "\n",
    "### Python Example\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset of daily returns (%) of a stock\n",
    "data = {'Daily Returns': [2, -1, 3, 4, 2, 2, 100, 1, 0, 2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Mean\n",
    "mean_return = df['Daily Returns'].mean()\n",
    "\n",
    "# Calculate Standard Deviation\n",
    "std_dev_return = df['Daily Returns'].std()\n",
    "\n",
    "# Calculate Coefficient of Variation\n",
    "cv_return = (std_dev_return / mean_return) * 100\n",
    "\n",
    "# Print Coefficient of Variation\n",
    "print(\"Coefficient of Variation of Daily Returns (%):\", cv_return)\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "\n",
    "- **Mean**: The average of the data points.\n",
    "- **Standard Deviation**: Measures the amount of variation or dispersion in the data set.\n",
    "- **Coefficient of Variation (CV)**: Provides a standardized measure of dispersion. If the CV is high, it indicates a higher level of dispersion around the mean. Conversely, a lower CV indicates less dispersion.\n",
    "\n",
    "### Application in Algorithmic Trading\n",
    "\n",
    "In algorithmic trading, the coefficient of variation can be used to:\n",
    "- **Risk Assessment**: Determine the risk associated with different trading strategies or assets by comparing their coefficients of variation. A higher CV might indicate a riskier asset.\n",
    "- **Performance Evaluation**: Compare the performance of models or funds that may operate across different scales of returns.\n",
    "\n",
    "By using CV, traders can make more informed decisions by understanding not just the variability of returns, but how that variability compares to the average returns, thereby adding an additional layer of risk management to their strategies.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Graphs for Univariate Analysis\n",
    "\n",
    "#### 1. **Frequency Distribution Table & Histogram**\n",
    "   - **Mathematical Description**: A histogram displays the distribution of data by forming bins along the range of the data and then drawing bars to show the number of observations that fall in each bin.\n",
    "   - **Python Code**:\n",
    "     ```python\n",
    "     import matplotlib.pyplot as plt\n",
    "     import pandas as pd\n",
    "     \n",
    "     # Sample data\n",
    "     data = {'Daily Returns': [2, -1, 3, 4, 2, 2, 100, 1, 0, 2]}\n",
    "     df = pd.DataFrame(data)\n",
    "\n",
    "     # Plotting Histogram\n",
    "     plt.hist(df['Daily Returns'], bins=10, color='blue', alpha=0.7)\n",
    "     plt.title('Histogram of Daily Returns')\n",
    "     plt.xlabel('Daily Returns (%)')\n",
    "     plt.ylabel('Frequency')\n",
    "     plt.show()\n",
    "     ```\n",
    "\n",
    "\n",
    "\n",
    "####  2. **Cumulative Frequency**\n",
    "- **Mathematical Description**: Cumulative frequency is used to determine the number of observations below a particular value in a dataset. It's calculated by successively adding each frequency from a frequency distribution table to the sum of its predecessors.\n",
    "  \n",
    "- **Python Code**:\n",
    "  ```python\n",
    "  import matplotlib.pyplot as plt\n",
    "  import pandas as pd\n",
    "\n",
    "  # Sample data\n",
    "  data = {'Daily Returns': [2, -1, 3, 4, 2, 2, 100, 1, 0, 2]}\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "  # Creating the frequency distribution for the 'Daily Returns'\n",
    "  frequency, bins = np.histogram(df['Daily Returns'], bins=10, range=[df['Daily Returns'].min(), df['Daily Returns'].max()])\n",
    "\n",
    "  # Calculating the cumulative frequency\n",
    "  cumulative_frequency = np.cumsum(frequency)\n",
    "\n",
    "  # Plotting the cumulative frequency graph\n",
    "  plt.plot(bins[1:], cumulative_frequency, marker='o', linestyle='-', color='b')\n",
    "  plt.title('Cumulative Frequency of Daily Returns')\n",
    "  plt.xlabel('Daily Returns (%)')\n",
    "  plt.ylabel('Cumulative Frequency')\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "  ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Graphs for Bivariate Analysis\n",
    "\n",
    "#### 1. **Categorical - Categorical: Contingency Table/Crosstab**\n",
    "   - **Mathematical Description**: A contingency table (or crosstab) summarizes the relationship between two categorical variables by showing the counts of intersections.\n",
    "   - **Python Code**:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     import matplotlib.pyplot as plt\n",
    "     import seaborn as sns\n",
    "     \n",
    "     # Sample data\n",
    "     data = {'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'A', 'B', 'C'],\n",
    "             'Outcome': ['Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No']}\n",
    "     df = pd.DataFrame(data)\n",
    "\n",
    "     # Creating a crosstab\n",
    "     contingency_table = pd.crosstab(df['Category'], df['Outcome'])\n",
    "     print(contingency_table)\n",
    "\n",
    "     # Plotting a heatmap of the crosstab\n",
    "     sns.heatmap(contingency_table, annot=True, cmap=\"YlGnBu\")\n",
    "     plt.title('Contingency Table of Category vs. Outcome')\n",
    "     plt.show()\n",
    "     ```\n",
    "\n",
    "#### 2. **Numerical - Numerical: Scatter Plot**\n",
    "   - **Mathematical Description**: A scatter plot maps individual data points for two numeric variables along two axes, providing a visual examination of the relationships or patterns in the data.\n",
    "   - **Python Code**:\n",
    "     ```python\n",
    "     import matplotlib.pyplot as plt\n",
    "\n",
    "     # Sample data\n",
    "     data = {'Variable1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "             'Variable2': [2, 3, 2, 5, 7, 8, 9, 10, 12, 11]}\n",
    "     df = pd.DataFrame(data)\n",
    "\n",
    "     # Plotting Scatter Plot\n",
    "     plt.scatter(df['Variable1'], df['Variable2'])\n",
    "     plt.title('Scatter Plot of Variable1 vs Variable2')\n",
    "     plt.xlabel('Variable1')\n",
    "     plt.ylabel('Variable2')\n",
    "     plt.grid(True)\n",
    "     plt.show()\n",
    "     ```\n",
    "\n",
    "#### 3. **Categorical - Numerical**\n",
    "   - **Mathematical Description**: This type of plot is used to visualize the relationship between a categorical variable and a numerical variable, often using box plots or bar charts to show distribution or average values respectively.\n",
    "   - **Python Code**:\n",
    "     ```python\n",
    "     import seaborn as sns\n",
    "     import matplotlib.pyplot as plt\n",
    "\n",
    "     # Sample data\n",
    "     data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "             'Value': [10, 20, 10, 30, 20, 40]}\n",
    "     df = pd.DataFrame(data)\n",
    "\n",
    "     # Plotting bar chart for categorical - numerical relationship\n",
    "     sns.barplot(x='Category', y='Value', data=df)\n",
    "     plt.title('Bar Chart of Categories and Values')\n",
    "     plt.xlabel('Category')\n",
    "     plt.ylabel('Value')\n",
    "     plt.show()\n",
    "     ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
